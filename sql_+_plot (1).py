# -*- coding: utf-8 -*-
"""SQL + PLot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fZ9pIA-pX4mkC5Xzm9n_21bKmWqSXDai
"""

!pip install -q -U langchain==0.1.2
!pip install -q -U google-generativeai==0.5.2
!pip install -q -U langchain-google-genai==1.0.3

!pip install langchain_google_genai langchain_community requests

import pandas as pd
import sqlite3

import os
import re
from langchain.chains import create_sql_query_chain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

# Convert CSV file into a SQL DB

csv_file_path = '/content/Healthcare_dataset_with_summary.csv'


df = pd.read_csv(csv_file_path)

database_path = 'data.db'


connection = sqlite3.connect(database_path)

df.to_sql('patients', connection, if_exists='replace', index=False)

query_result = pd.read_sql('SELECT * FROM patients', connection)
print(query_result.head())

connection.close()

from langchain_community.utilities import SQLDatabase

db_path = '/content/data.db'
db = SQLDatabase.from_uri(f"sqlite:///{db_path}")
print(db.dialect)
print(db.get_usable_table_names())
db.run("SELECT * FROM patients LIMIT 10;")

os.environ["GOOGLE_API_KEY"] = ""

# llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key='', convert_system_message_to_human=True, temperature=0.0)

llm = ChatGoogleGenerativeAI(model="gemini-pro", convert_system_message_to_human=True, temperature=0.0)
chain = create_sql_query_chain(llm, db)
response = chain.invoke({"question": "What is the count occurence of all blood groups in the data?"})


regex_pattern = r'^```sql\n|\n```$'


modified_response = re.sub(regex_pattern, '', response)
print(modified_response)

db.run(modified_response)

"""### MAIN CODE"""

import pandas as pd
import sqlite3
import os
import re
from langchain.chains import create_sql_query_chain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate

# Convert CSV file into a SQL DB
csv_file_path = '/content/Healthcare_dataset_with_summary.csv'
df = pd.read_csv(csv_file_path)
database_path = 'data.db'
connection = sqlite3.connect(database_path)
df.to_sql('patients', connection, if_exists='replace', index=False)

# Execute SQL query and load results into a DataFrame
query_result = pd.read_sql('SELECT * FROM patients', connection)
print(query_result.head())

from langchain_community.utilities import SQLDatabase
db_path = '/content/data.db'
db = SQLDatabase.from_uri(f"sqlite:///{db_path}")
print(db.dialect)
print(db.get_usable_table_names())

# Set up LLM for generating SQL
os.environ["GOOGLE_API_KEY"] = ""
llm = ChatGoogleGenerativeAI(model="gemini-pro", convert_system_message_to_human=True, temperature=0.0)
chain = create_sql_query_chain(llm, db)

# Process the user query and fetch results as a DataFrame
response = chain.invoke({"question": "What is the count occurrence of all blood groups in the data?"})
modified_response = re.sub(r'^```sql\n|\n```$', '', response)

# Convert query result to DataFrame
df_query_result = pd.read_sql_query(modified_response, connection)
print(df_query_result)

!pip install langchain-experimental

import pandas as pd
import sqlite3
import os
import re
from langchain.chains import create_sql_query_chain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate


# Convert CSV file into a SQL DB
csv_file_path = '/content/Healthcare_dataset_with_summary.csv'
df = pd.read_csv(csv_file_path)
database_path = 'data.db'
connection = sqlite3.connect(database_path)
df.to_sql('patients', connection, if_exists='replace', index=False)

# Execute SQL query and load results into a DataFrame
query_result = pd.read_sql('SELECT * FROM patients', connection)
print(query_result.head())

from langchain_community.utilities import SQLDatabase
db_path = '/content/data.db'
db = SQLDatabase.from_uri(f"sqlite:///{db_path}")
print(db.dialect)
print(db.get_usable_table_names())

# Set up LLM for generating SQL
os.environ["GOOGLE_API_KEY"] = "AIzaSyDdIZ******"
llm = ChatGoogleGenerativeAI(model="gemini-pro", convert_system_message_to_human=True, temperature=0.0)
chain = create_sql_query_chain(llm, db)

response = chain.invoke({"question": "What is the count occurrence of all blood groups in the data?"})
modified_response = re.sub(r'^```sql\n|\n```$', '', response)

df_query_result = pd.read_sql_query(modified_response, connection)
print(df_query_result)


from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent as experimental_pandas_agent


pandas_agent = create_pandas_dataframe_agent(llm, df_query_result)

pandas_query = "Show me the average age of patients by blood group"
agent_result = pandas_agent.run(pandas_query)
print(agent_result)

pip uninstall langchain langchain-core langchain-experimental

pip install langchain==0.0.349 langchain-core==0.0.13 langchain-experimental

pip install langchain==0.0.349 langchain-experimental

pip install langchain-experimental --upgrade

pip install -e

pip install langchain==0.0.349

pip install langchain-core

pip install langchain==0.2.16





















# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade --quiet  langchain e2b langchain-community

'''import os
import pandas as pd
import sqlite3
from langchain.chains import create_sql_query_chain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import E2BDataAnalysisTool

# Set up environment variables for API keys
os.environ["GOOGLE_API_KEY"] = ""
os.environ["E2B_API_KEY"] = ""

# Database setup
csv_file_path = '/content/Healthcare_dataset_with_summary.csv'
database_path = 'data.db'
connection = sqlite3.connect(database_path)
df = pd.read_csv(csv_file_path)
df.to_sql('patients', connection, if_exists='replace', index=False)

# Initialize E2BDataAnalysisTool
e2b_data_analysis_tool = E2BDataAnalysisTool()

# Set up the LLM for generating SQL
llm = ChatGoogleGenerativeAI(model="gemini-pro", convert_system_message_to_human=True, temperature=0.0)

# Create SQL query chain with E2B Data Analysis
chain = create_sql_query_chain(llm, e2b_data_analysis_tool)

# User query example
user_query = "What is the count occurrence of all blood groups in the data?"
response = chain.invoke(user_query)

# Assuming the response includes SQL queries and matplotlib chart generation
# This part would automatically handle chart generation and possibly return an image or a path to the saved chart
print(response)

# Close the database connection
connection.close()

'''

pip install --upgrade e2b





!pip uninstall langchain langchain-core langchain-experimental langchain-community -y

!pip install langchain  langchain-experimental langchain-core google-generativeai langchain-google-genai pandas numpy matplotlib

import pandas as pd
import sqlite3
import os
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_google_genai import ChatGoogleGenerativeAI

# Database setup
csv_file_path = '/content/Healthcare_dataset_with_summary.csv'
database_path = 'data.db'
connection = sqlite3.connect(database_path)
df = pd.read_csv(csv_file_path)
df.to_sql('patients', connection, if_exists='replace', index=False)

# Execute SQLquery and loading results into DataFrame
query = "SELECT Blood_Type, COUNT(*) as count FROM patients GROUP BY Blood_Type"
df_query_result = pd.read_sql_query(query, connection)
print(df_query_result)

os.environ["GOOGLE_API_KEY"] = ""
llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0)


pandas_agent = create_pandas_dataframe_agent(
    llm,
    df_query_result,
    verbose=True
)


pandas_query = "Show me the average age of patients by blood group"
agent_result = pandas_agent.run(pandas_query)
print(agent_result)

# Closing the database connection
connection.close()



"""Pandas Agent Testing"""

from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
from langchain.schema import AgentType
import pandas as pd


df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35]
})


from langchain.llms import GoogleGemini


llm = GoogleGemini(api_key="")


agent = create_pandas_dataframe_agent(
    llm=llm,
    df=df,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    include_df_in_prompt=True,
    number_of_head_rows=3
)


response = agent.run("What is the average age?")
print(response)

from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
import pandas as pd

# Sample Dataframe
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35]
})


from langchain.llms import GoogleGemini
llm = GoogleGemini(api_key="")

# Creating the pandas DataFrame agent
agent = create_pandas_dataframe_agent(
    llm=llm,
    df=df,
    verbose=True,
    include_df_in_prompt=True,
    number_of_head_rows=3
)

# Example usage
response = agent.run("What is the average age?")
print(response)